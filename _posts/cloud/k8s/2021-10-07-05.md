---
title:  "k8s 05. 컨트롤러 (워크로드 리소스)"
excerpt:

categories:
  - k8s

toc: true
toc_sticky: true
 
date: 2021-10-07
last_modified_at: 2021-10-08
---



# 1. 워크로드 리소스 (컨트롤러)

* 파드는 직접 다루지 않는다. 컨트롤러로 파드들을 관리한다

* 워크로드 리소스를 사용하여 파드 생성 관리 장애시 복제 및 롤아웃(release) 자동복구 처리

* 용어

  * 컨테이너 (워크로드)
  * 파드 : 컨테이너 집합
  * 레플리케이션 : 파드 복제 집합, **파드 유지**
  * 디플로이먼트 : 레플리케이션의 배포 기능 세분화, **파드(앱) 배포**
  * 스테이트풀셋 : 파드 상태 추적 관리
  * 데몬셋 : 전체 노드에 같은 파드 실행, 파드 관리
* 컨테이너 -> 파드 -> 레플리카셋 -> 디플로이먼트



# 2. 레플리카셋

## 2-1. 개념

* 파드의 복제, 확장
* 레플리케이션 컨트롤러 : 지정된 숫자만큼 파드가 클러스터에서 실행되도록 관리, 파드 유지
* 레플리카셋 : 레플리케이션의 발전형, 명시된 동일 파드 개수에 대한 가용성을 보증

## 2-2. 특징

* 파드마다 lable 설정
* 집합 기반 셀렉터 지원 : in, notin, exists
* rolling-update 사용안됨 (레플리케이션은 됨 -> 디플로이먼트에서 사용)

## 2-3. 템플릿

* replicas : 유지하는 파드 개수
* selector : 유지하는 파드를 식별 -> 템플릿의 메타데이터.레이블에서 일치하는 레이블의 컨테이너를 찾아 파드를 유지한다
  * selector.matchLabels
* template : 유지하는 파드에 대한 정보
  * template.metadata.labels : **`spec.template.metadata.labels`는 `spec.selector`와 일치해야 함**
  * template.spec : 컨테이너의 spec

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # 1. replicas : 유지하는 파드 개수
  replicas: 3
  # 2. selector : 유지하는 파드를 식별
  selector:
  	################
    matchLabels:
      tier: frontend
    ################
      
  # 3. template : 파드에 대한 정보
  template:
    # 3-1. metadata
    metadata:
      ################
      labels:
        tier: frontend
      ################
    # 3-2. spec
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google_samples/gb-frontend:v3
```

## 2-4. 작업

```shell
# 레플리카셋 실행
kubectl apply -f 레플리카셋파일

# 확인
kubectl get rs
kubectl describe rs/레플리카셋이름
kubectl get pods

# 레플리카셋, 파드 삭제 : 레플리카셋을 삭제하면 파드도 같이 삭제된다.
kubectl delete rs <rs 이름>

# 레플리카셋만 삭제하기
kubectl delete rs <rs이름> --cascade=orphan
```



# 3. 디플로이먼트

## 3-1. 개념

* 파드와 레플리카셋에 대한 선언적 업데이트 제공
* 디플로이먼트로 파드의 생성과 삭제 그리고 업데이트를 오케스트레이션하는 메커니즘으로 사용
  * 레플리카셋을 사용 할 수 있지만, 기본적으로 디플로이먼트를 사용한다.
* stateless 앱을 배포할 때 사용하는 가장 기본적인 컨트롤러
* 파드 유지 + 앱 배포시 롤링 업데이트 + 롤백 + 일시정지

## 3-2. 템플릿

* `1(metadata.labels) == 2(spec.selector.matchlabels) == 3(spec.template.matadata)`
* 디플로이먼트에는 파드 템플릿 레이블과 적절한 셀렉터를 반드시 명시해야 한다.
* 레이블 또는 셀렉터는 다른 컨트롤러와 겹치지 않아야 한다.

```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: nginx-deployment # 디플로이먼트 이름
  # 레이블-------
  labels:                # 셀렉터, 템플릿에 사용할 레이블
    app: nginx
  # -----------
    
spec:
  # 1. 레플리카 파드 개수
  replicas: 3
  
  # 2. 셀렉터
  selector:
  	# 레이블-------
    matchLabels:
      app: nginx
    # -----------
      
  # 3. 템플릿
  template:
    # 3-1. 메타데이터
    metadata:
    # 레이블-------
      labels:
        app: nginx
    # -----------
    
    # 3-2. 스펙
    spec:
      containers:
      - name: nginx         # 레이블에 적혀있는 이름
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

## 3-3. 작업

```shell
# 생성
$ kubectl apply -f <디플로이먼트파일>

# 확인
$ kubectl get deployments
$ kubectl get rs
$ kubectl get pods --show-labels
$ kubectl rollout status deployment/<디플로이먼트 이름>
```

## 3-4. 롤링 업데이트, 롤백, 스케일링, 일시정지, 재개

```shell
# 1. 롤링 업데이트---------------------------------------------------------------------------------
# 업데이트를 하면, 새로운 것 하나 업하고, 기존 것은 하나 다운, 이런 식으로 업데이트를 한다.

# 롤 아웃 기록 확인 (컨테이너 이미지 변경 내역)
$ kubectl rollout status deployment/<디플로이먼트 이름>

# 롤링 업데이트
$ kubectl set image deployment/<디플로이먼트> <업데이트 할 이미지>
$ kubectl set image deployment/<디플로이먼트> <컨테이너이름>=<업데이트 할 이미지>
* 업데이트이미지 -> 컨테이너이미지:버전숫자

$ kubectl edit deployment.v1.apps/<디플로이먼트 이름>
-> 템플릿 수정 -> apply

# 2. 롤백----------------------------------------------------------------------------------------
# 1. 이전 레플리카셋, 파드 확인 -> 고착상태 확인
kubectl get rs
kubectl get pods
kubectl describe deployment

# 2. 롤아웃 기록 확인
kubectl rollout history deployment.v1.apps/<디플로이먼트 이름>
kubectl rollout history deployment.v1.apps/<디플로이먼트 이름> --revision=<번호> # 수정 번호의 세부정보 보기

# 3. 롤백
kubectl rollout undo deployment.v1.apps/<디플로이먼트>
kubectl rollout undo deployment.v1.apps/<디플로이먼트 이름> --to-revision=<번호>

# 3. 스케일링-------------------------------------------------------------------------------------
 # 파드의 개수를 조정
kubectl scale deployment.v1.apps/<디플로이먼트> --replicas=<개수>
kubectl autoscale deployment.v1.apps/<디플로이먼트> --min=<최소개수> --max=<최대개수> --cpu-percent=<사용률>

# 4. 일시중지, 재개--------------------------------------------------------------------------------
# 일시중지
kubectl rollout pause deployment.v1.apps/<디플로이먼트>

# 업데이트
kubectl set image deployment.v1.apps/<디플로이먼트> <옵션>

# 재개
kubectl rollout resume deployment.v1.apps/<디플로이먼트>
kubectl rollout restart deployment/<디플로이먼트>

# 롤 아웃 상태 확인
kubectl get rs -w
kubectl rollout status deployment/<디플로이먼트>
```

## 3-5. Deployment Spec

* .spec.strategy

  * 이전 파드를 새로운 파드로 대체하는 전략

  * .spec.strategy.type==RollingUpdate : 롤링업데이트 방식으로 업데이트, maxUnavailable, maxSurge 명시
    * maxUnavailable : 업데이트 프로세스 중에 사용할 수 없는 최대 파드의 수
    * maxSurge : 디플로이먼트에 설정된 기본 파드 개수에 추가할 수 있는 최대 파드의 수 (추가할 수 있는 여분의 파드)
  * .spec.strategy.type==Recreate : 기존의 파드는 새 파드가 생성되기 전에 죽음

* .spec.progressDeadlineSeconds : 디플로이먼트 fail을 알리기 전에, 디플로이먼트가 진행되는 것을 대기시키는 시간



# 4. 데몬셋

## 4-1. 개념

* 클러스터 전체 노드에 특정 파드를 실행할 떄 사용하는 컨트롤러, 파드 관리
* 목적 : 모든 노드에서 클러스터 스토리지 데몬 or 로그 수집 데몬 or 노드 모니터링 데몬 실행

## 4-2. 템플릿

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-elasticsearch
  # 1. 네임스페이스
  namespace: kube-system # 쿠버네티스 관리
  # 2. 레이블
  labels:
    k8s-app: fluentd-logging
    
spec:
	# 1. 셀렉터
  selector:
    matchLabels:
      name: fluentd-elasticsearch
  # 2. 템플릿
  template:
    # 2-1. 메타데이터
    metadata:
      labels:
        name: fluentd-elasticsearch
    
    # 2-2. 스펙
    spec:
      containers:
      - name: fluentd-elasticsearch
        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
```

* 데몬셋 spec

  * .spec.updateStrategy.type
    * RollingUpdate
      * maxUnavailable : 한번에 삭제하는 파드 개수
    * OnDelete : 데몬셋으로 실행한 파드를 직접 지워야 해당 노드에 새로운 템플릿 버전의 파드가 실행됨
  * .spec.minReadySeconds : 새로 실행하는 파드가 준비 상태가 되는 최소 시간
  * .spec.template.spec
    * nodeSelector : 노드 셀렉터와 일치하는 노드에 파드를 생성
    * .spec.template.spec.affinity : 노드 어피니티와 일치하는 노드에 파드를 생성

* 명령어

  ```shell
  # 실행
  kubectl apply -f <데몬셋>
  
  # 확인
  kubectl get daemonset -n kube-system
  
  # 수정
  kubectl edit daemonset <데몬셋> -n kube-system
  ```

  



# 5. 스테이트풀셋

## 5-1. 개념

### 1. Stateful & Stateless
> Stateful & Stateless (https://www.redhat.com/ko/topics/cloud-native-apps/stateful-vs-stateless)
>
> Stateless : 단일 요청에 대한 하나의 응답 (검색)
>
> Stateful : 이전 트랜잭션에서 발생한 상황에 영향을 받음. 컨텍스트와 내역이 저장되므로 중단되어도 중단된 곳부터 다시 시작할 수 있다. 같은 사람과 주기적으로 대화 하는 것

### 2. 스테이트풀셋
* stateful한 파드들을 관리하는 컨트롤러
* 디플로이먼트, 레플리카셋, 레플리케이션 컨트롤러는 stateless한 파드들을 관리
* 용도 : 고유한 네트워크 식별자, 스토리지, 순차적인 정상배포와 스케일링, 롤링 업데이트
* 스테이트풀셋을 삭제 또는 스케일 다운해도 스테이트풀셋과 연관된 볼륨이 *삭제되지 않는다*. 이는 일반적으로 스테이트풀셋과 연관된 모든 리소스를 자동으로 제거하는 것보다 더 중요한 데이터의 안전을 보장하기 위함이다.
* 파드 배포
  * 순차적으로 생성하고, 역순으로 종료된다.
  * 선행파드가 running이 되어야지 다음 파드가 생성되고, 역순으로 종료되어야지 다음 파드도 종료된다.

## 5-2. 템플릿

```yaml
# 서비스
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  clusterIP: None
  selector:
    app: nginx
    
---
# 스테이트풀셋
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  # 스테이트풀 셋에서 설정할 서비스네임
  serviceName: "nginx"
  
	# 1. 레플리카
  replicas: 3
  
  # 2. 셀렉터
  selector:
    ##############
    matchLabels:
      app: nginx
    ##############
    
  # 3. 템플릿
  template:
    # 메타데이터
    metadata:
      ##############
      labels:
        app: nginx
      ##############
    # 스펙
    spec:
      terminationGracePeriodSeconds: 10 # gracefull : 실행중인 프로세스를 종료할 때 작업을 마무리하고 정상종료 하는 것
      containers:
      - name: nginx
        image: k8s.gcr.io/nginx-slim:0.8
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
          
  # 4. volume 템플릿
  volumeClaimTemplates:
  - metadata:
      name: www
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "my-storage-class"
      resources:
        requests:
          storage: 1Gi
```



## 5-3. Identity, 볼륨, 헤드리스 서비스

### 1. Pod Identity

파드 호스트 네임 : {스테이트풀셋 name}-{0...N-1}

스테이트풀셋 도메인 :  {서비스네임}.{서비스네임스페이스}.svc.cluster.local

파드 DNS : {파드 호스트 네임}.{스테이트풀셋 도메인}

### 2. Persistant Volume (PV)

* Persistant Volume (PV)
  * 컨테이너가 죽더라도, 데이터는 유지해야 할 때 사용하는 볼륨
  * 퍼시스턴트 볼륨은 파드 또는 스테이트풀셋이 삭제되더라도 삭제되지 않는다.
* PersistentVolumeClaim (PVC) : 사용자가 PV에 요청하는 것 
  * 용량, read/write mode
* 참고 : https://arisu1000.tistory.com/27849

### 3. headless service

* 서비스에 대한 IP나 로드밸런싱이 필요없는 서비스
* 서비스의 IP가 없는 대신, 파드의 IP를 직접 가리킨다.



## 5-4. 스테이트풀셋 업데이트

* .spec.podManagementPolicy
  * OrderedReady : 순차적 파드 관리
  * Paraller : 모든 파드를 병렬로 실행, 종료, 다른 파드를 기다리지 않음
* .spec.updateStrategy
  * RollingUpdate : 템플릿 변경시 자동으로 예전 파드 삭제, 새로운 파드를 실행
    * partition : 파티션보다 작은 수를 가진 모든 파드는 업데이트 하지 않음
  * type
    * OnDelete : 템플릿 변경시, 수동으로 스테이트풀셋에 속한 파드들을 삭제했을 떄, 새로운 파드를 실행





# 6. 잡

## 6-1. 개념

* 실행 후 종료해야 하는 성격의 작업을 실행시킬 때 사용하는 컨트롤러
* 특정 개수만큼의 파드를 정상적으로 실행 종료함을 보장
* 단일 잡으로 사용하는 것이 좋다.

## 6-2. 템플릿

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
      # 동일한
  backoffLimit: 4 # 잡이 실패 했을 때, 재시작 최대 횟수
```

* 확인 : kubectl logs <파드>

## 6-3. Job Spec

### 1. 병렬성 관리

* 잡 하나가 몇 개의 파드를 동시에 실행할 것인가
* .spec.parallelism
  * 주어진 시간에 잡을 실행시킬 때 실행되는 최대 파드의 개수
  * default 1 /// 0 이면 잡 정지
  * 설정 값보다 잡이 파드를 적게 실행 시킬 수도 있다.
* .spec.completions
  * 잡을 실행 했을 때 성공적으로 종료되어야 하는 파드의 개수
  * .spec.completionMode
    * NonIndexed
    * Indexed
* 병렬성 타입 (.spec.parallelism / .spec.completions)
  1. Non-parallels Job : (-/-)
  2. Parallel Jobs with a fixed completion count (고정적인 완료 횟수를 가진 병렬 잡) : (-/설정)
  3. Parallel Jobs wit a work queue (작업 큐가 있는 병렬 잡) : (설정/설정하지 않아도 parallelism과 동일하게 설정됨)

### 2. 장애처리

* `.spec.template.spec.restartPolicy` : 컨테이너 재시작 정책
  * 파드 내 컨테이너 비정상 종료시 (메모리 사용량 제한 초과, 비정상 종료 등)
  * Onfailure : 컨테이너를 재시작 한다.
  * Never : 재시작을 막는다. 잡에서 새로운 파드를 실행한다.
  * 파드는 동시성에 대해서도 관대(tolerant)해야 한다.
* `.spec.backoffLimit` : 잡을 실패로 간주하기 이전에 재시도할 횟수를 설정한다.

### 3. 종료

* 잡이 완료되면 파드가 더 이상 생성되지도 않지만, 삭제되지도 않는다. 이를 유지하면 완료된 파드의 로그를 계속 보며 에러, 경고 또는 다른 기타 진단 출력을 확인할 수 있다. 

* `.spec.activeDeadlineSeconds` : 지정된 시간에 해당 잡을 강제로 종료, 모든 파드 실행도 종료

* 명령어를 사용할 경우

  ```shell
  kubectl delete jobs/잡
  kubectl delete -f ./job.yaml
  ```

  



# 7.크론잡

* 주기적인 잡

* 백업 실행 or 정기적, 반복적 작업

* 템플릿

  ```yaml
  apiVersion: batch/v1
  kind: CronJob
  metadata:
    name: hello
  spec:
  	# 크론잡 schedule
    schedule: "*/1 * * * *"
    
    # 잡 템플릿
    jobTemplate:
      spec:
        template:
          spec:
            containers:
            - name: hello
              image: busybox
              imagePullPolicy: IfNotPresent
              command:
              - /bin/sh
              - -c
              - date; echo Hello from the Kubernetes cluster
            restartPolicy: OnFailure
  ```


* startingDeadlineSeconds : 기존 작업이 진행 중일 경우, 새로운 작업이 실행하기 위해 대기하는 시간
* concurrencyPolicy: 병렬처리 방식 결정(allow / forbid / replace )









