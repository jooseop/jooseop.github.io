---
title:  "Aiffel python 7. Big Data, MapReduce"
excerpt:

categories:
  - python

toc: true
toc_sticky: true
 
date: 2021-12-24
---



# Big Data

### 많은 데이터를 처리하는 방법

1. 병렬 컴퓨팅(Parallel Computing), 분산 컴퓨팅(Distributed Computing), 클러스터 컴퓨팅(Cluster Computing)
2. 맵리듀스(Mapreduce)



### 대용량 처리를 위한 컴퓨팅

병렬 컴퓨팅(Parallel Computing)

* 한 대의 컴퓨터 안에서 CPU 코어를 여러 개 사용해서 한 대의 컴퓨터가 처리하는 데이터의 총량과 처리속도를 증가시키는 것
* 멀티프로세스 (Multiprocessing), 멀티스레드 (Multithreading)

분산 컴퓨팅(Distributed Computing)

* 여러 대의 컴퓨터가 네트워크로 연결된 상황을 전제

* P2P(Peer to Peer), HTTP, Network

클러스터 컴퓨팅(Cluster Computing)

* 여러 대의 컴퓨터들이 연결되어 하나의 시스템처럼 동작하는 컴퓨터들의 집합 (노드와 관리자로 구성)
* 병렬컴퓨팅, 분산컴퓨팅, 클라우드 컴퓨팅
* 클러스터에서 어떻게 데이터를 교환할 것인가, 클러스터로 데이터 서버를 관리 할때, 파일 시스템을 어떻게 연결할 것인가



### 빅데이터 처리 패턴

**Split-Apply-Combine Strategy** (많은 데이터를 잘게 나누기 - 처리하기 - 합치기)

맵리듀스 : Split - Map - Shuffle - Reduce







# MapReduce

### MapReduce

빅데이터용 클러스터 컴퓨팅에 사용되는 주요 프로그래밍 모델    
`map()` : **Split**된 부분을 가져와 조작을 하는, **Apply** 역할을 하는 함수 // map - key, value 자료구조  
`reduce()` : map()함수가 만들어낸 결과물을 기준에 따라 모으는, **Combine** 역할을 하는 함수 // 맵을 줄여나간다.

<img width="846" src="https://user-images.githubusercontent.com/65662520/147343578-6ecf4f91-8b47-48cb-b043-adccd5a285da.png">

* 출처 : [*MapReduce: Simplified Data Processing on Large Clusters - Jeffrey Dean and Sanjay Ghemawat*](https://static.googleusercontent.com/media/research.google.com/ko//archive/mapreduce-osdi04.pdf)



### MapReduce Programming Model

input : split 단계를 전제, in_key, in_value     
`map (in_key, in_value)` -> `list(out_key, intermediate_value`   
`reduce (out_key, list(intermediate_value))` -> `list(out_value)`

 <img width="773" src="https://user-images.githubusercontent.com/65662520/147340423-5473b2e1-c87a-4eaf-8678-7aa91c23448d.png">

* 출처 : [MapReduce: Simplified Data Processing on Large Clusters - Google Research](https://research.google.com/archive/mapreduce-osdi04-slides/index.html)



### Big Data Ecosystem

Big Data Ecosystem : 데이터 수집(Data Ingestion) - 데이터 처리(Data Processing) - 데이터 분석(Data Analysis) - 데이터 검색(Data Exploration)

하둡(Hadoop)

* 대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈소스 프레임워크
* map 함수 종료 후 reduce 함수가 실행된다는 성능 손실 때문에 배치성 작업(일괄적으로 모아서 처리)에 사용, 실시간 작업 약점
* HDFS 분산 파일 시스템을 제공

스파크(Spark)

* 하둡 기반의 빅데이터 생태계를 이루는 주요한 컴포넌트로 어울려 존재함
*  map 함수가 전부 종료되지 않았더라도 Map의 결과를 스트리밍하는 방식
    * 데이터를 메모리에 적재하여 사용하는 인메모리 데이터 엔진을 통해 초기 맵리듀스의 성능상 한계를 극복
    * In-memory 기반 클러스터 컴퓨팅 데이터 처리 프로그램
* 클러스터 환경에서 동작 (클라우드), Scala 기반, Programming - Library - Engine - Management - Storage      





# Functional Programming

### 함수형 프로그래밍

함수형 프로그래밍의 함수

- 함수는 다른 함수의 인자로 전달될 수 있다. (= 인자(매개변수)로 전달이 가능)
- 함수는 변수에 할당될 수 있다.
- 함수는 다른 함수의 결과로서 반환될 수 있다. (=다른 함수의 반환값)

함수형 프로그래밍 철학

1. 변경 가능한 상태를 불변의 상태(Immutable)로 만들어 에러를 없애자. 
2. 모든 것은 객체이다. 
3. 코드를 간결하게 하고 가독성을 높여 구현할 로직에 집중한다. 
4. 보다 효율적인 동시성 작업

함수형 프로그래밍 언어

* Python, Javascript, Scala, Go 등
* 아닌 언어 : C, Java 등

python & bigdata

* 빅데이터, 대용량의 자료를 표현할 때 `python`의 `collections(container)` 모듈을 통해 저장한다.
* 함수를 인자로 받는 함수형 프로그래밍 -> 방식이 미리 정해져 있지 않음 -> 유연하다는 것이 강점



### MapReduce Function

1. map() : 컬렉션의 모든 요소에 함수를 적용(=매핑)

    * `M(x): x ∈ C`

    ```python
    map(function, iterable, ...)
    ```

    ```python
    mynum = ['1','2','3','4']
    mynum_int = list(map(int, mynum))
    print(mynum_int) # [1, 2, 3, 4]
    
    mynum_square = list(map(lambda x : x*x, mynum_int))
    print(mynum_square) # [1, 4, 9, 16]
    ```

2. filter() : 컬렉션 내의 요소를 선택(=필터링)

    * `x: x ∈ C, ifF(x)`

    ```python
    filter(function, iterable)
    ```

    ```python
    mynum = range(-5, 5)
    mynum_plus = list(filter(lambda x: x > 0, mynum))
    print(mynum_plus) # [1, 2, 3, 4]
    ```

3. reduce() : 컬렉션을 축약 (ex, 시그마)

    *   `∑ _{x ∈ C} x`

    ```python
    from functools import reduce
    reduce(function, iterable[, initializer]) # BNF 표기 - [] : 선택적으로 사용
    ```

    ```python
    from functools import reduce
    mynum = [1, 2, 3, 4, 5]
    add = reduce((lambda x, y: x + y), mynum)
    print(add) # 15
    ```

